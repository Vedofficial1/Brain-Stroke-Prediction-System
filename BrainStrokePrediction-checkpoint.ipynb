{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimblearn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mib\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      8\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mFutureWarning\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# The libraries used in processing the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn as ib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe is read from the csv file - healthcare-dataset-stroke-data.csv - taken from kaggle\n",
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 5 instances of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the number of NULL values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of N/A values in eacg column\n",
    "print(df.isna().sum())\n",
    "# Graphical representation of the na values present in the attribute - bar graph\n",
    "df.isna().sum().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Found 201 NULL values in bmi column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the  statistical analysis of all numerical type attributes  (count, mean, standaard deviation, minimum values, all quartiles, maximum values)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides the data type of all attributes and the number of NOT NULL values count is obtained\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE PROCESSING + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'id' column is dropped since the attribute holds no significant importance to the problem at hand\n",
    "df = df.drop(['id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values in the gender column\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have a 'other' gender and since there is only 1 instance we will remove it as to reduce the dimension of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the 'other' gender instance inorder to reduce the dimension\n",
    "df['gender'] = df['gender'].replace('Other','Female')\n",
    "# plotting a pie chart to see the gender count distribution\n",
    "df['gender'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are more females as compared to males "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target feature - Stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stroke analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count in the stroke attribute\n",
    "df['stroke'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of the value count distribution of the target attribute\n",
    "df['stroke'].value_counts().plot(kind=\"bar\",color = \"cyan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"% of people who actualy got a stroke : \",(df['stroke'].value_counts()[1]/df['stroke'].value_counts().sum()).round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our dataset is highly skewed since only around 5% of the instances got stroke \n",
    "* We will be needing to perform necessary transformations to improve samples of minority class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-tension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of the value counts of the hypertension attribute\n",
    "df['hypertension'].value_counts().plot(kind=\"bar\",color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value of count of work-type attribute\n",
    "df['work_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of the value counts of the work-type attribute\n",
    "df['work_type'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoking status Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value of count of somoking status attribute\n",
    "df['smoking_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of the value counts of the smoking staus attribute\n",
    "df['smoking_status'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residence type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value of count of residence attribute\n",
    "df['Residence_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of the value counts of the residence attribute\n",
    "df['Residence_type'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have an equal percentage of population who are from Urban and rural areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of BMI - NULL values\n",
    "df['bmi'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We only have N/A values in bmi column - 201 Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of bmi attribute\n",
    "sns.histplot(data=df['bmi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bmi is rightly skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df['bmi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on the histogram and boxplot we see that there are many outliers in bmi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the count of outliers based on those instances which are out of iqr \n",
    "Q1 = df['bmi'].quantile(0.25)\n",
    "Q3 = df['bmi'].quantile(0.75)\n",
    "# Finding IQR\n",
    "IQR = Q3 - Q1\n",
    "da=(df['bmi'] < (Q1 - 1.5 * IQR)) | (df['bmi'] > (Q3 + 1.5 * IQR))\n",
    "da.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Total outliers in bmi:110\n",
    "* Total non-outliers in bmi:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of NULL values in bmi\n",
    "df['bmi'].isna().sum()/len(df['bmi'])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NULL values hold 3.93 % of the instances in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na=df.loc[df['bmi'].isnull()]\n",
    "g=df_na['stroke'].sum()\n",
    "print(\"People who got stroke and their BMI is NA:\",g)\n",
    "h=df['stroke'].sum()\n",
    "print(\"People who got stroke and their BMI is given:\",h)\n",
    "print(\"percentage of people with stroke in Nan values to the overall dataset:\",g/h*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of instances who got stroke\n",
    "df['stroke'].sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our main target function is stroke And the instances who got a stroke is in the minority - 249  Which is only 4.9 % of the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing whether to drop NA values in Bmi column\n",
    "df_na=df.loc[df['bmi'].isnull()]\n",
    "print(\"Nan BMI values where people have stroke:\",df_na['stroke'].sum())\n",
    "print(\"overall BMI values where people have stroke:\",df['stroke'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Among the 201 bmi NULL values 40 values in them got stroke \n",
    "* Thus we cant drop NULL values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since there are outliers present we canâ€™t perform mean imputation as mean is affected by the outliers\n",
    "* Hence we impute it with median values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the missing N/A values using the median of bmi column\n",
    "print(\"median of bmi\",df['bmi'].median())\n",
    "df['bmi']=df['bmi'].fillna(df['bmi'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation fo the data in age column\n",
    "# histogram\n",
    "sns.histplot(data=df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot\n",
    "sns.boxplot(data=df['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The age parameter values does not have any outliers\n",
    "* And has a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVERAGE GLUCOSE LEVEL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation fo the data in glucose level column\n",
    "# histogram\n",
    "sns.histplot(data=df['avg_glucose_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "sns.boxplot(data=df['avg_glucose_level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are many outliers present based on the boxplot and histogram \n",
    "* The data is positively skewed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the count of outliers based on those instances which are out of iqr \n",
    "Q1 = df['avg_glucose_level'].quantile(0.25)\n",
    "Q3 = df['avg_glucose_level'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "da=(df['avg_glucose_level'] < (Q1 - 1.5 * IQR)) | (df['avg_glucose_level'] > (Q3 + 1.5 * IQR))\n",
    "da.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Total outliers in avg_glucose_level : 627\n",
    "* Total non-outliers in avg_glucose_level : 4483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix between the attributes in the dataset to find if any attributes are correlated\n",
    "corrmat=df.corr()\n",
    "f,ax=plt.subplots(figsize=(9,8))\n",
    "sns.heatmap(corrmat,ax=ax,cmap=\"YlGnBu\",linewidth=0.8,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is  a weak correlation between the attributes as per the plotted heatmap\n",
    "* The highest correlation found was between age and bmi - 0.32\n",
    "* Rest all correlations were less than 0.32\n",
    "* We could not drw any statistical insight from heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart_disease analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count of heart disease attribute\n",
    "df['heart_disease'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This data reflects that around 94.5 % of the total population or list of people are free from Heart_disease and only 6.5 % are having heart_disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['heart_disease'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ever_married analysis with Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count of evver married attribute\n",
    "df['ever_married'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This result shows that 65.6 % of people from the list are married and 34.4 % are unmarried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation\n",
    "df['ever_married'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross analysis - all the attribute compared with target attibute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing stroke with gender\n",
    "sns.countplot(x='stroke', hue='gender', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing stroke with work-type\n",
    "sns.countplot(x='stroke', hue='work_type', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on this comparison we see in the provided dataset that people who never worked never got a heart attack and the people who are privetly employed got more strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing stroke with somking_status\n",
    "sns.countplot(x='stroke', hue='smoking_status', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on the plot we can that those who formerly smoked got more strokes The people who smoked and never smoked has a somewhat same probability of getting stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing stroke with residence type\n",
    "sns.countplot(x='stroke', hue='Residence_type', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on the analysis the people who live in Urban areas were reported with more strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing stroke with heart disease\n",
    "sns.countplot(x='stroke', hue='heart_disease', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This plotting shows that the number of \"people with Strokes but no heart disease\" is approximately 6 to 8 times the number of \"people with Strokes and also heart disease\". This shows most of the people with no heart disease are suffering with Strokes compared to the once who have Heart Disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing stroke with married status\n",
    "sns.countplot(x='stroke', hue='ever_married', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This plotting shows that the number of \"Married people with Strokes\" is approximately 10 to 12 times the no. \"Unmarried people with Strokes\". \n",
    "* This shows most of the Married people got Strokes compared to Unmarried people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy variables for numeric-binary attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting numeric-binary value attributes to string\n",
    "df[['hypertension', 'heart_disease', 'stroke']] = df[['hypertension', 'heart_disease', 'stroke']].astype(str)\n",
    "# Generating dummy attributes - one hot encoding format\n",
    "df = pd.get_dummies(df, drop_first= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data frame after performing dummy attributes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our Dataset is highly undersampled (based on target instances) we are going to perform a over sampling method to have equal representation of both the target classes\n",
    "# Using random oversampling - importing the library \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Performing a minority oversampling\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X=df.drop(['stroke_1'],axis=1)\n",
    "y=df['stroke_1']\n",
    "\n",
    "# Obtaining the oversampled dataframes - testing and training\n",
    "X_over, y_over = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing a scaling modeule\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Since the numeric attributes in the dataset is in different ranges and three are outliers persent we are usign a scaler to get all the values into the same range.\n",
    "s = StandardScaler()\n",
    "# Scaling the numeric attributes\n",
    "df[['bmi', 'avg_glucose_level', 'age']] = s.fit_transform(df[['bmi', 'avg_glucose_level', 'age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scaling the numeric values for bringing them all to the same scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating test-train split (80-20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_over' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[39m# Performing a 80-20 test-train split\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X_over, y_over, test_size\u001b[39m=\u001b[39m \u001b[39m0.20\u001b[39m, random_state\u001b[39m=\u001b[39m \u001b[39m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_over' is not defined"
     ]
    }
   ],
   "source": [
    "# creating dataset split for training and testing the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Performing a 80-20 test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size= 0.20, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the size of the splits \n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m clf \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[0;32m     10\u001b[0m \u001b[39m# Training the classifier\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     13\u001b[0m \u001b[39m#predicting result using the test dataset\u001b[39;00m\n\u001b[0;32m     14\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#importing the Decision Tree Classifier module\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Libraries for calculating performance metrics\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import auc,roc_auc_score,roc_curve,precision_score,recall_score,f1_score\n",
    "\n",
    "# Create the classifier object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Training the classifier\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#predicting result using the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Printing the accuracyof the model\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the KNN Classifier module\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Libraries for calculating performance metrics\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.metrics import auc,roc_auc_score,roc_curve,precision_score,recall_score,f1_score\n",
    "\n",
    "# Create the classifier object\n",
    "# 2 neighbours because of the 2 classes\n",
    "knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "# Training the classifier\n",
    "knn.fit(X_train,y_train)\n",
    "#predicting result using the test dataset\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_prob_knn = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Printing the accuracy and roc-auc score of the model\n",
    "confusion_matrix(y_test, y_pred_knn)\n",
    "print('Accuracy:',accuracy_score(y_test, y_pred_knn))\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred_prob_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the XGBoost Classifier module\n",
    "from xgboost  import XGBClassifier\n",
    "\n",
    "# Create the classifier object\n",
    "xgb = XGBClassifier()\n",
    "# Training the classifier\n",
    "xgb.fit(X_train,y_train)\n",
    "#predicting result using the test dataset\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_pred_prob_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Printing the accuracy and roc-auc score of the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred_prob_xgb))\n",
    "\n",
    "# plots of roc_auc \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_xgb)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, linewidth=2, color= 'teal')\n",
    "plt.plot([0,1], [0,1], 'r--' )\n",
    "plt.title('ROC Curve of XGBOOST')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix of the model\n",
    "from sklearn.metrics import plot_confusion_matrix,precision_recall_fscore_support\n",
    "plot_confusion_matrix(xgb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the precision,recall,f1score and support values of the model based on the confusion matrix\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "print(\"Accuracy_score:\",accuracy_score(y_test,y_pred_xgb))\n",
    "print(\"Precision_score:\",precision_score(y_test,y_pred_xgb))\n",
    "print(\"Recall_score:\",recall_score(y_test,y_pred_xgb))\n",
    "print(\"f1_score:\",f1_score(y_test,y_pred_xgb))\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred_prob_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing random forest classifier module for training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the classifier object\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Train the model using the training sets\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# performing predictions on the test dataset\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Printing accuracy of the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing module for kfold cross validation\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Performing k fold cross validation using 20 splits\n",
    "kfold_kridge = model_selection.KFold(n_splits=20, shuffle=True)\n",
    "results_kfold = model_selection.cross_val_score(rf_clf, X_over, y_over, cv=kfold_kridge)\n",
    "print(\"Accuracy: \", results_kfold.mean()*100)\n",
    "print(results_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix,precision_recall_fscore_support\n",
    "plot_confusion_matrix(rf_clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = classifier.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred_lr)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sample predictions based on manual value entry\n",
    "age=75\n",
    "avg_glucose_level=300\n",
    "bmi=36.6\n",
    "gender_Male=1\n",
    "ever_married_Yes=1\t\n",
    "work_type_Never_worked=0\t\n",
    "work_type_Private=1\t\n",
    "work_type_Self_employed=0\n",
    "work_type_children=0\t\n",
    "Residence_type_Urban=1\n",
    "smoking_status_formerly_smoked=1\n",
    "smoking_status_never_smoked=0\n",
    "smoking_status_smokes=0\n",
    "hypertension_1=1\n",
    "heart_disease_1=1\n",
    "input_features = [age\t,avg_glucose_level,\tbmi\t,gender_Male,hypertension_1,\theart_disease_1,ever_married_Yes,\twork_type_Never_worked,\twork_type_Private,\twork_type_Self_employed,\twork_type_children\t,Residence_type_Urban,\tsmoking_status_formerly_smoked,smoking_status_never_smoked\t,smoking_status_smokes]\n",
    "\n",
    "features_value = [np.array(input_features)]\n",
    "features_name = ['age'\t,'avg_glucose_level',\t'bmi'\t,'gender_Male'\t,'hypertension_1',\t'heart_disease_1','ever_married_Yes',\t'work_type_Never_worked',\t'work_type_Private',\t'work_type_Self-employed',\t'work_type_children'\t,'Residence_type_Urban',\t'smoking_status_formerly smoked','smoking_status_never smoked'\t,'smoking_status_smokes']\n",
    "\n",
    "df = pd.DataFrame(features_value, columns=features_name)\n",
    "prediction = rf_clf.predict(df)[0]\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the front end \n",
    "import pickle\n",
    "\n",
    "with open('model.pickle','wb') as f:\n",
    "  pickle.dump(rf_clf,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
